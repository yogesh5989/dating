{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3de641e7-af49-44bc-ae0c-d28024666345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: largeDoses, the real answer is: smallDoses\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: largeDoses, the real answer is: didntLike\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: largeDoses, the real answer is: didntLike\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: smallDoses, the real answer is: largeDoses\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: largeDoses, the real answer is: largeDoses\n",
      "the classifier came back with: smallDoses, the real answer is: smallDoses\n",
      "the classifier came back with: didntLike, the real answer is: didntLike\n",
      "the classifier came back with: largeDoses, the real answer is: didntLike\n",
      "the total error rate is: 0.05\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "percentage of time spent playing video games?  10\n",
      "frequent flier miles earned per year?  10000\n",
      "liters of ice cream consumed per year?  0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will probably like this person: smallDoses\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 1: Function to load data from file and process it into a matrix and a list of labels\n",
    "def file2matrix(filename):\n",
    "    # Open the file\n",
    "    fr = open(filename)\n",
    "    # Count the number of lines in the file to determine the size of the matrix\n",
    "    numberOfLines = len(fr.readlines())\n",
    "    # Initialize a matrix to hold the feature data (3 features per sample) \n",
    "    returnMat = np.zeros((numberOfLines, 3))\n",
    "    # Initialize a list to hold class labels (e.g., 'didntLike', 'smallDoses', 'largeDoses')\n",
    "    classLabelVector = []\n",
    "    # Re-open file to start reading data from the beginning\n",
    "    fr = open(filename)\n",
    "    # Initialize index for each row of the matrix\n",
    "    index = 0\n",
    "    for line in fr.readlines():\n",
    "        # Remove any leading/trailing whitespaces\n",
    "        line = line.strip()\n",
    "        # Split each line by tab ('\\t') to separate features and label\n",
    "        listFromLine = line.split('\\t')\n",
    "        # Store the first three items as features in the matrix\n",
    "        returnMat[index, :] = listFromLine[0:3]\n",
    "        # Store the last item as a label in the list\n",
    "        classLabelVector.append(listFromLine[-1])\n",
    "        # Increment the index for the next row\n",
    "        index += 1\n",
    "    return returnMat, classLabelVector\n",
    "\n",
    "# Step 2: Function to normalize the dataset\n",
    "def autoNorm(dataSet):\n",
    "    # Calculate the minimum values for each feature column\n",
    "    minVals = dataSet.min(0)\n",
    "    # Calculate the maximum values for each feature column\n",
    "    maxVals = dataSet.max(0)\n",
    "    # Calculate the range (max - min) for each feature column\n",
    "    ranges = maxVals - minVals\n",
    "    # Create an array of zeros with the same shape as the input dataset\n",
    "    normDataSet = np.zeros(np.shape(dataSet))\n",
    "    # Get the number of rows in the dataset\n",
    "    m = dataSet.shape[0]\n",
    "    # Subtract the minimum values from the dataset and scale by dividing by the range\n",
    "    normDataSet = dataSet - np.tile(minVals, (m, 1))\n",
    "    normDataSet = normDataSet / np.tile(ranges, (m, 1))\n",
    "    return normDataSet, ranges, minVals\n",
    "\n",
    "# Step 3: k-Nearest Neighbors algorithm for classification\n",
    "def classify0(inX, dataSet, labels, k):\n",
    "    # Calculate the number of samples in the dataset\n",
    "    dataSetSize = dataSet.shape[0]\n",
    "    # Calculate the difference matrix between inX and each sample in the dataset\n",
    "    diffMat = np.tile(inX, (dataSetSize, 1)) - dataSet\n",
    "    # Square the difference matrix\n",
    "    sqDiffMat = diffMat**2\n",
    "    # Sum the squared differences for each row to get squared Euclidean distances\n",
    "    sqDistances = sqDiffMat.sum(axis=1)\n",
    "    # Calculate the square root of each element to get the Euclidean distances\n",
    "    distances = sqDistances**0.5\n",
    "    # Get the indices of the distances in ascending order\n",
    "    sortedDistIndices = distances.argsort()\n",
    "    # Dictionary to count the occurrence of each label among the k nearest neighbors\n",
    "    classCount = {}\n",
    "    for i in range(k):\n",
    "        # Find the label of the i-th nearest neighbor\n",
    "        voteIlabel = labels[sortedDistIndices[i]]\n",
    "        # Count the label in the dictionary\n",
    "        classCount[voteIlabel] = classCount.get(voteIlabel, 0) + 1\n",
    "    # Sort the class count dictionary by occurrence in descending order\n",
    "    sortedClassCount = sorted(classCount.items(), key=lambda item: item[1], reverse=True)\n",
    "    # Return the label with the highest count (most common among neighbors)\n",
    "    return sortedClassCount[0][0]\n",
    "\n",
    "# Step 4: Function to test classifier accuracy\n",
    "def datingClassTest():\n",
    "    # Set hold-out ratio for testing (10%)\n",
    "    hoRatio = 0.10\n",
    "    # Load and process the data file\n",
    "    datingDataMat, datingLabels = file2matrix('datingTestSet.txt')\n",
    "    # Normalize the feature matrix\n",
    "    normMat, ranges, minVals = autoNorm(datingDataMat)\n",
    "    # Get the total number of samples\n",
    "    m = normMat.shape[0]\n",
    "    # Calculate the number of samples to use as the test set\n",
    "    numTestVecs = int(m * hoRatio)\n",
    "    # Initialize error count to track misclassifications\n",
    "    errorCount = 0.0\n",
    "    # Loop over each test sample\n",
    "    for i in range(numTestVecs):\n",
    "        # Classify the test sample and get the predicted label\n",
    "        classifierResult = classify0(normMat[i, :], normMat[numTestVecs:m, :], datingLabels[numTestVecs:m], 3)\n",
    "        # Print the predicted and actual label for the test sample\n",
    "        print(f\"the classifier came back with: {classifierResult}, the real answer is: {datingLabels[i]}\")\n",
    "        # Increment error count if the prediction is incorrect\n",
    "        if classifierResult != datingLabels[i]:\n",
    "            errorCount += 1.0\n",
    "    # Print the total error rate (errors / test samples)\n",
    "    print(f\"the total error rate is: {errorCount / float(numTestVecs)}\")\n",
    "\n",
    "# Step 5: Function to predict the match type for a new person based on input features\n",
    "def classifyPerson():\n",
    "    # Labels list for possible match outcomes\n",
    "    resultList = ['didntLike', 'smallDoses', 'largeDoses']\n",
    "    # Prompt the user to enter the percentage of time spent playing video games\n",
    "    percentTats = float(input(\"percentage of time spent playing video games? \"))\n",
    "    # Prompt the user to enter the number of frequent flyer miles earned per year\n",
    "    ffMiles = float(input(\"frequent flier miles earned per year? \"))\n",
    "    # Prompt the user to enter the liters of ice cream consumed per year\n",
    "    iceCream = float(input(\"liters of ice cream consumed per year? \"))\n",
    "    # Load and process the dating data file\n",
    "    datingDataMat, datingLabels = file2matrix('datingTestSet.txt')\n",
    "    # Normalize the dataset (to get ranges and minVals)\n",
    "    normMat, ranges, minVals = autoNorm(datingDataMat)\n",
    "    # Create an array for the new input features\n",
    "    inArr = np.array([ffMiles, percentTats, iceCream])\n",
    "    # Normalize the input array using the training data's minVals and ranges\n",
    "    classifierResult = classify0((inArr - minVals) / ranges, normMat, datingLabels, 3)\n",
    "    # Print the prediction (i.e., the likely match type)\n",
    "    print(\"You will probably like this person:\", classifierResult)\n",
    "\n",
    "# Step 6: Load and normalize data, test classifier accuracy, and classify a new person\n",
    "# Uncomment below to test functions interactively:\n",
    "datingDataMat, datingLabels = file2matrix('datingTestSet.txt')\n",
    "normMat, ranges, minVals = autoNorm(datingDataMat)\n",
    "datingClassTest()\n",
    "classifyPerson()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f98aba19-cece-419d-b974-747af413110c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.0920000e+04, 8.3269760e+00, 9.5395200e-01],\n",
       "       [1.4488000e+04, 7.1534690e+00, 1.6739040e+00],\n",
       "       [2.6052000e+04, 1.4418710e+00, 8.0512400e-01],\n",
       "       ...,\n",
       "       [2.6575000e+04, 1.0650102e+01, 8.6662700e-01],\n",
       "       [4.8111000e+04, 9.1345280e+00, 7.2804500e-01],\n",
       "       [4.3757000e+04, 7.8826010e+00, 1.3324460e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datingDataMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c3d2f4-3bcb-464a-9db7-61a08f71870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#small dose 10,10000,0.5\n",
    "#large dose 10 50000, 0.4\n",
    "#didn't like it 13 75000 1.2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
